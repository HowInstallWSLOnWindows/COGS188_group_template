{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You have the choice of doing either (1) an AI solve a problem style project or (2) run a Special Topics class on a topic of your choice.  This repo is assuming you want to do (1).  If you want to do (2) you should fill out the Gradescope proposal for that instead of using this repo.\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like 8-Queens or a small Traveling Salesman Problem or similar\n",
    "- If its the kind of problem (e.g., RL) that interacts with a simulator or live task, then the problem will have a reasonably complex action space. For instance, a wupus world kind of thing with a 9x9 grid is definitely too small.  A simulated mountain car with a less complex 2-d road and simplified dynamics seems like a fairly low achievement level.  A more complex 3-d mountain car simulation with large extent and realistic dynamics, sure sounds great!\n",
    "- If its the kind of problem that uses a dataset, then the dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training an unsupervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "- The project must include some elements we talked about in the course\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "\n",
    "- Kenny Wu\n",
    "- Areen Lu\n",
    "- Chaska Kentish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "The goal of our project is stock portfolio management through the use of Artificial Intelligence to optimize the portfolio based on risk-return profiles. The risk-return profiles refer to the trade-off between potential returns and risk of losing money. The data used consists of historical stock prices, average returns, and the covariance matrix of the stocks. By using the date, we will develop a simulated annealing algorithm model to construct and optimize the portfolios based on the given risk and return profiles. The performance and success of the model(s) will be evaluated by the Sharpe ratio, which evaluates the risk-adjusted returns and expected returns. A ratio above 1.0 on Sharpe indicates good performance, and anything under indicates it is suboptimal. (115) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Stock portfolio management has made huge advancements due to the dominant growing field of Artificial Intelligence. This can be seen in the optimization of portfolios based on risk-return profiles. The risk-return trade-off is a fundamental concept in Economics. In the stock market, risk refers to the measurable uncertainties that exist, where certain probabilities can be linked to outcomes based on historical data/models. This is known to Knight as measurable risks(insert #1 footnote). However, the unmeasurable certainties still exist within the stock market and add another layer of complexity. This is known as true uncertainty and as a result, those who are able to navigate through it, get profit as a reward. (insert #1 footnote) In our project, however, we must not only maximize returns, but also minimize risk as it is impossible to predict the unmeasurable uncertainties.\n",
    "\n",
    "For the project, we will focus on the principles of Modern Portfolio Theory, aka MPT, which was introduced by Markowitz, which allow for investors to build an optimal portfolio that results in the highest expected return for a given level of risk. (insert footnote #3) It works by using the mean and variance to measure expected returns and risk. As AI continues to grow and develop, it has introduced new methods for portfolio optimization. Reinforcement learning, text mining, sentiment analysis, and deep learning are only some of the many techniques that are being used to adjust portfolios dynamically. We are using historical data, average returns, and the covariance matrix as our main inputs which is a well supported approach in portfolio management and optimization. This allows us to calculate returns and see how different stocks change over time in relation to each other, allowing us to evaluate the performance and how volatile the market is while maintaining diversification. \n",
    "\n",
    "Our goal is to use this data for a simulated annealing algorithm AI model(?) that can construct and optimize portfolios based on specific risk and return profiles. This will be measured using the Sharpe ratio. The Sharpe ratio evaluates risk adjusted returns by comparing the excess return of the portfolio over the risk-free rate to its standard deviation. (insert footnote #2) Any ratio above 1.0 on Sharpe indicates good performance, while any ratio under indicates it is suboptimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The problem we aim to solve is maximization of return while minimizing risk for those who have risk-return profiles. Current portfolio management rely on static models, and they fail to adapt to an ever-changing stock market. Which could risk investors being vulnerable to excessive risk or suboptimal returns. Our goal is to develop an A.I. driven model that can analyze vast quantities of historical stock data, calculate average returns, and evaluate the covariance between stocks to construct optimized portfolios. This problem is quantifiable, as we can calculate average returns and a quantifiable value for the covariance between stocks. We can measure this through the Sharpe ratio, which is used for measuring risk-adjusted relative returns (insert #2 footnote)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data we will be using will be from Yahoo Finance, which will be imported to python as yfinance as yf. This dataset has a large amount of variables which include opening price, closing price, high price, low price, adjusted closing price, trading volume, profit margins, and gross margins. yfinance offers observations on the date, opening price of stock, highest price of the stock for that day, lowest price of the stock for that day, the adjusted closing price of stock for the day, and the trade volume for the day. This would give us 7 * 365 observations if we were to look at only one stock for the past year. Some important observations would be the date which is represented Year-Month-Day. Additionally, it gives us the time. Other important observations like adjusted closing is represented a floating number, while trade volume is represented as integer. Lastly the stock ticker, the stock identifier, is represented as a string. Some important things to note is that there might be missing data. This will result in use using the data from the day prior or the day after to fill in. \n",
    "Additionally, We may look into other data sets to help improve our AI driven model as large amounts of data is necessary to improve on our model such that it will be beneficial to the user instead of a detriment to them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "The algorithm that we are leaning towards is the simulated annealing algorithm. Itg is a metaheuristic optimization algorithm that explores the solution space with uphill probability moves and aims to converge to an optimal solution. This provides the framework for constructing and optimizing portfolios based on specific risk and return lines in the stock market domain.\n",
    "\n",
    "Algorithm Description: \n",
    "- Initialization: initial portfolio allocation \n",
    "- Function: objective function to evaluate performance using Sharpe, expected return, risk, and risk free rate\n",
    "- Simulated Annealing Loop: iterate until terminate criterion is met, make small changes/allocations in the portfolio, evaluate function for new allocation, accept or reject new allocation, update parameter to schedule \n",
    "\n",
    "Implementation: \n",
    "- Dataset preparation: stock price date +risk-free data for given time period\n",
    "- Use objective function to calc Sharpe ratio based on portfolio\n",
    "- Simulated Annealing implementation\n",
    "- Testing and Validation \n",
    "\n",
    "There will exist a benchmark model used for comparison which would be a static portfolio allocations based on the traditional methods without the AI optimization. We would construct it using mean-variance or some other strategy. This would allow us to gain insights in how effective our solution is once implemented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "The evaluation metric we will choose to use is the Sharpe ratio. The Sharpe ratio is one of the most widely used methods for measuring risk adjusted returns. For this, we will need 3 variables: expected return, risk, and risk-free rate.  \n",
    "Thus our Sharpe ratio will be equal to (returns - risk-free rate)/risk. This will give us our Sharpe ratio. We will evaluate this ratio following the metrics outlined by Sharpe himself. Where anything below 1.0 is considered suboptimal, while anything above will be considered good. Where the higher the value of the Sharpe ratio, the better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want this model to: \n",
    "- Use stock data that is widely available to the public\n",
    "- No invasion of privacy. We won’t use the user’s data as a way to get more information that would improve our model. No specific user’s data\n",
    "- Ensure that everyone has fair access to the model\n",
    "- Include explanations that are clear, so the user will be able to make full use of the model. \n",
    "- Not participate in behavior that could be viewed as manipulation of the stock market.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our team, we expect that everyone sufficiently and properly stays in communication regards to any part of the project whether it’s code, literature, etc. We also expect that everyone contributes fairly with a somewhat equal splitting of tasks; it does not have to be across all aspects of the project as long as all members feel it is fair (i.e. someone focusing more on code vs someone focusing more on writing). In the case of an emergency or some other thing that is preventing someone from working, receiving sufficient notice would be appreciated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 1-2: Data Gathering, Data Preparation and Preprocessing\n",
    "\n",
    "Week 3-4:Model Development, Testing and Validation\n",
    "\n",
    "Week 5-6: Performance Evaluation and Optimization\n",
    "\n",
    "Week 7-8: Finalization and Documentation\n",
    "\n",
    "Week 9-10: Final Review and Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "https://fraser.stlouisfed.org/files/docs/publications/books/risk/riskuncertaintyprofit.pdf\n",
    "\n",
    "https://www.investopedia.com/terms/s/sharperatio.asp\n",
    "\n",
    "https://www.frontiersin.org/articles/10.3389/frai.2024.1371502/full\n",
    "\n",
    "https://pypi.org/project/yfinance/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
